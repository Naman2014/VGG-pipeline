{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.models import Model,  Sequential\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, Dropout, BatchNormalization, Activation\n",
    "from sklearn.metrics import confusion_matrix , classification_report, accuracy_score, recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating dataset code named gen_seg.ipynb\n",
    "# dividing dataset named split.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the datasets\n",
    "\n",
    "# Base directory where your datasets are located\n",
    "base_dir = r'E:\\Desktop\\Carselona\\Gate open or close\\dataset'\n",
    "\n",
    "train_path = os.path.join(base_dir, 'train')\n",
    "val_path = os.path.join(base_dir, 'val')\n",
    "# test_path = os.path.join(base_dir, 'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing the images of each class\n",
    "for folder in os.listdir(train_path):\n",
    "    sub_path = train_path + \"/\" + folder\n",
    "    print(folder)\n",
    "    for i in range(2):\n",
    "        temp_path = os.listdir(sub_path)[i]\n",
    "        temp_path = sub_path + \"/\" + temp_path\n",
    "        img = mpimg.imread(temp_path)\n",
    "        implot = plt.imshow(img)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert image into  pixels here feature is edge\n",
    "def imagearray(path, size):\n",
    "    data = []\n",
    "    for folder in os.listdir(path):\n",
    "        sub_path = os.path.join(path, folder)\n",
    "        for img in os.listdir(sub_path):\n",
    "            image_path = os.path.join(sub_path, img)\n",
    "            img_arr = cv.imread(image_path)\n",
    "\n",
    "            # Resize the image\n",
    "            img_arr = cv.resize(img_arr, size)\n",
    "\n",
    "            # Apply Canny on a copy of a channel (e.g., grayscale)\n",
    "            edge_mask = cv.Canny(img_arr[:, :, 0], 40, 200)\n",
    "\n",
    "            # Create a 3-channel image by stacking the edge mask along the third axis\n",
    "            edge_img = np.stack([edge_mask] * 3, axis=-1)\n",
    "\n",
    "            data.append(edge_img)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size is 250 * 250 for VGG\n",
    "size = (250,250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply above convert function on train test val \n",
    "train = imagearray(train_path,size)\n",
    "val = imagearray(val_path,size)\n",
    "# test = imagearray(test_path,size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation\n",
    "x_train = np.array(train)\n",
    "x_val   = np.array(val)\n",
    "# x_test  = np.array(test)\n",
    "\n",
    "x_train = x_train/255\n",
    "x_val   = x_val/255\n",
    "# x_test  = x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the input shape .... must be 4 channel (n , 250,250, 3) where n is number of images\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining target variables\n",
    "def data_class(data_path, size, class_mode):\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "    classes = datagen.flow_from_directory(data_path, target_size= size, batch_size = 32, class_mode = class_mode)\n",
    "    return classes\n",
    "\n",
    "train_class = data_class(train_path, size,\"sparse\")\n",
    "val_class   = data_class(val_path, size, \"sparse\")\n",
    "# test_class  = data_class(test_path, size, \"sparse\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_class.classes\n",
    "y_val = val_class.classes\n",
    "# y_test = test_class.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion to class index\n",
    "train_class.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check shape\n",
    "print(y_train.shape,y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise VGG\n",
    "vgg = VGG19(input_shape = (250,250,3) , weights = \"imagenet\" , include_top = False)\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = Flatten()(vgg.output)\n",
    "prediction = Dense(2, activation = \"softmax\")(x)\n",
    "\n",
    "model = Model(inputs = vgg.input, outputs = prediction)\n",
    "model.summary()\n",
    "\n",
    "early_stop = EarlyStopping(monitor = \"val_loss\" , mode= \"min\", verbose=1, patience = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model architecture\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\",\n",
    "              optimizer = \"adam\",\n",
    "              metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model ..set epochs 50+ \n",
    "history = model.fit(x_train,y_train,\n",
    "          validation_data = (x_val,y_val),\n",
    "          epochs = 15,\n",
    "          callbacks = [early_stop],\n",
    "          batch_size = 30,\n",
    "          shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'model' is your trained Keras model save it\n",
    "model.save('test_door.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting accuracy\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(history.history['accuracy'], label='train acc')\n",
    "plt.plot(history.history['val_accuracy'], label='val acc')\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "\n",
    "# Specify the path and filename to save the plot\n",
    "save_path = 'metrices\\accuracy_plot.png' \n",
    "\n",
    "# Save the plot to the specified file\n",
    "plt.savefig(save_path)\n",
    "\n",
    "# Must be increasing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting loss\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.title('Loss')\n",
    "\n",
    "# Specify the path and filename to save the plot\n",
    "save_path_loss = 'metrices\\loss_plot.png'  # Change this to your desired filename and path for loss plot\n",
    "\n",
    "# Save the loss plot to the specified file\n",
    "plt.savefig(save_path_loss)\n",
    "\n",
    "# must be decreasing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "# before doing this uncomment the test folder everywhere\n",
    "model.evaluate(x_test, y_test, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction for metrices\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 score\n",
    "print('F1 score:\\t')\n",
    "f1_score(y_test,y_pred, average = 'micro')\n",
    "\n",
    "# recall_score\n",
    "print('recall_score: \\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision score\n",
    "print('precision_score:\\t')\n",
    "precision_score(y_test, y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion metric \n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 16})\n",
    "\n",
    "# Add labels, title, and ticks\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xticks([0.5, 1.5], ['Predicted 0', 'Predicted 1'])\n",
    "plt.yticks([0.5, 1.5], ['Actual 0', 'Actual 1'])\n",
    "\n",
    "# Specify the path and filename to save the plot\n",
    "save_path_conf = 'metrices\\confusion_metric.png' \n",
    "\n",
    "# Save the loss plot to the specified file\n",
    "plt.savefig(save_path_conf)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vgg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
